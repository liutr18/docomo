{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "720910c1-b2c8-4c1f-afc8-b759c3ce5436"
   },
   "outputs": [],
   "source": [
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "8e4bccd0-e03d-47b7-9b0d-6ecdc56b83dd"
   },
   "outputs": [],
   "source": [
    "#for docomo, 9 CUDAs are available in total, we only use CUDA 0 is this program\n",
    "num_device = torch.cuda.device_count()\n",
    "print('There are '+str(num_device)+' GPUs. We will use CUDA 0 in this program.')\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5271f257-fcc0-4a4f-8bb2-1a089c39a4ec"
   },
   "outputs": [],
   "source": [
    "#assign parameter values\n",
    "input_nodes=512\n",
    "output_nodes=512\n",
    "middle_nodes=512\n",
    "test_rate=0.2\n",
    "max_epoch=100\n",
    "lr=1e-3\n",
    "dropout_rate=0.05\n",
    "num_BS=4\n",
    "num_beam=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "62f189c6-57b9-45ed-a947-59af332bc3f4"
   },
   "outputs": [],
   "source": [
    "#load datasets from .mat files\n",
    "in_set_file = loadmat('DLCB_Dataset/DLCB_input.mat')\n",
    "in_set = in_set_file['DL_input']#in_set.shape=(54481,256)\n",
    "out_set_file = loadmat('DLCB_Dataset/DLCB_output.mat')\n",
    "out_set = out_set_file['DL_output']#out_set.shape=(54481,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5a75a283-5ed0-4f66-8b2b-70b94aa09c6f"
   },
   "outputs": [],
   "source": [
    "#define a Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_nodes,middle_nodes)\n",
    "        self.fc2 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc3 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc4 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc5 = nn.Linear(middle_nodes,output_nodes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 4 hidden layers with each fc + relu + dropout\n",
    "        x = x.to(device)\n",
    "        x = x.view(-1,512)\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc2(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc3(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc4(x)),p = dropout_rate,training = True)\n",
    "        # 1 output layer with fc + relu\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x  \n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "\n",
    "#define Loss Function and Optimization method\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "282e5f1b-888d-4e1f-99a1-0e9b05ac2d5b"
   },
   "outputs": [],
   "source": [
    "class DataSetGenerator(data.Dataset):\n",
    "    def __init__(self,input_set,output_set):\n",
    "        self.input_set = input_set\n",
    "        self.output_set = output_set\n",
    "     \n",
    "    def __getitem__(self,index):\n",
    "        x=[]\n",
    "        for j in range(self.input_set.shape[1]):\n",
    "            x.append(self.input_set[index][j])\n",
    "        label=[]\n",
    "        for j in range(self.output_set.shape[1]):\n",
    "            label.append(self.output_set[index][j])\n",
    "        return torch.FloatTensor(x),torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ebf4628b-64cd-44af-861b-66db7e497635"
   },
   "outputs": [],
   "source": [
    "#get num_total_user from in_set\n",
    "def getTotalUser(in_set):\n",
    "    num_total_user=in_set.shape[0]\n",
    "    ##print('Number of total users in input dataset is '+str(num_total_user))\n",
    "    return num_total_user\n",
    "num_total_user = getTotalUser(in_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "9658202d-c041-489c-971a-8607054a3fa1"
   },
   "outputs": [],
   "source": [
    "#get DL_size_list, 17 percentages are fixed according to the author\n",
    "def getDLSizeList():\n",
    "    DL_pr_list = [.001,.05,.1,.15,.2,.25,.3,.35,.4,.45,.5,.55,.6,.65,.7,.75,.8]\n",
    "    DL_size_list = []\n",
    "    for i in range(len(DL_pr_list)):\n",
    "        DL_size_list.append(int(DL_pr_list[i]*num_total_user))\n",
    "    ##print('Number of users in DL is '+str(DL_size_list))\n",
    "    return DL_size_list\n",
    "DL_size_list = getDLSizeList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a3ac6b8c-c1f5-4b51-aaa4-7082c7b434d4"
   },
   "outputs": [],
   "source": [
    "#get num_train and num_test, both are lists according to DL_size_list, num_total_user, test_rate\n",
    "def getAmount(DL_size_list,num_total_user,test_rate):\n",
    "    num_train=[]\n",
    "    num_test=[]\n",
    "    for i in range(len(DL_size_list)):\n",
    "        num_train.append(int((DL_size_list[i])*0.8))\n",
    "        num_test.append(int(num_total_user*test_rate))\n",
    "    ##print(str(num_train)+' training examples.\\n'+str(num_test)+' test examples.')\n",
    "    return num_train,num_test\n",
    "num_train,num_test = getAmount(DL_size_list,num_total_user,test_rate)\n",
    "##print(len(num_train)==len(num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "8df73c08-ea6c-4234-8595-faf1d86c2291"
   },
   "outputs": [],
   "source": [
    "#specifically for the i-th DL_size, return its in_train_pre,in_test_pre,out_train_pre,out_test_pre(all before any adjustments)\n",
    "def eachInOutPre(i,num_train,num_test,num_total_user,in_set,out_set):\n",
    "    train_index = np.random.choice(range(0,num_total_user),size=num_train[i],replace=False)\n",
    "    rem_index = set(range(0,num_total_user))-set(train_index)\n",
    "    test_index = list(set(np.random.choice(list(rem_index),size=num_test[i],replace=False)))\n",
    "    in_train_pre = in_set[train_index]\n",
    "    in_test_pre = in_set[test_index]\n",
    "    out_train_pre = out_set[train_index]\n",
    "    out_test_pre = out_set[test_index]\n",
    "    return in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index\n",
    "##in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index = eachInOutPre(2,num_train,num_test,num_total_user,in_set,out_set)\n",
    "##print(in_train_pre.shape,out_train_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5836b5ee-368b-4b68-a503-3ddc4f9ca585"
   },
   "outputs": [],
   "source": [
    "#arrange input into real part and imaginary part one by one\n",
    "def arrangeInput(lst):\n",
    "    order = np.zeros((lst.shape[0],2*lst.shape[1]))\n",
    "    for i in range(lst.shape[0]):\n",
    "        for j in range(lst.shape[1]):\n",
    "            order[i][2*j] = np.float64(lst[i][j].real)\n",
    "            order[i][2*j+1] = np.float64(lst[i][j].imag)\n",
    "    return order\n",
    "##in_train = arrangeInput(in_train_pre)\n",
    "##in_test = arrangeInput(in_test_pre)\n",
    "##print(in_train_pre[12][85],in_train[12][85*2],in_train[12][85*2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "537b735b-1c60-470c-9ed8-58de7262c49e"
   },
   "outputs": [],
   "source": [
    "#specificially for i BS(s) in usage, divide output columns by num_beam\n",
    "def divideOutput(i,num_BS,num_beam,lst):\n",
    "    out = np.zeros((lst.shape[0],int(lst.shape[1]*(1/num_BS))))\n",
    "    for j in range(lst.shape[0]):\n",
    "        for k in range(int(lst.shape[1]*(1/num_BS))):\n",
    "            out[j][k] = lst[j][k+i*num_beam]\n",
    "    return out\n",
    "##out_train = divideOutput(2,num_BS,num_beam,out_train_pre)\n",
    "##out_test = divideOutput(2,num_BS,num_beam,out_test_pre)\n",
    "##print(out_train_pre.shape[1]==2048,out_train.shape[1]==512)\n",
    "##print(out_train_pre[12][85+1024],out_train[12][85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b28be5e3-c4e2-46a0-9945-2f2521eb24d3"
   },
   "outputs": [],
   "source": [
    "#for the i_DL-th DL_size and i_Out BS(s), generate and load datasets, where i_DL 0-16, i_Out 0-3\n",
    "def getLoader(i_DL,i_Out):\n",
    "    in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    in_train = arrangeInput(in_train_pre)\n",
    "    in_test = arrangeInput(in_test_pre)\n",
    "    out_train = divideOutput(i_Out,num_BS,num_beam,out_train_pre)\n",
    "    out_test = divideOutput(i_Out,num_BS,num_beam,out_test_pre)\n",
    "\n",
    "    train_generator = DataSetGenerator(input_set = in_train, output_set = out_train)\n",
    "    train_loader = data.DataLoader(dataset=train_generator, batch_size=100,shuffle=True)\n",
    "    \n",
    "    test_generator = DataSetGenerator(input_set = in_test, output_set = out_test)\n",
    "    test_loader = data.DataLoader(dataset=test_generator, batch_size=10,shuffle=True)\n",
    "    return train_loader,test_loader,in_test,out_test\n",
    "##train_loader,test_loader,in_test,out_test = getLoader(12,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "055ff1bd-9e0e-4c17-945d-639e5c2b5f3b"
   },
   "outputs": [],
   "source": [
    "#every 50 epochs, print a loss statistics, flag is set to be 0 if it is a training set, otherwise 1\n",
    "def printS(i_DL,i_Out,epoch,loss,flag):\n",
    "    if epoch%50==49:\n",
    "        DL_size_list = getDLSizeList()\n",
    "        num_train,num_test = getAmount(DL_size_list,num_total_user,test_rate)\n",
    "        if flag==0:\n",
    "            print('Current DL size is {}, including {} BS.\\nCurrent Training Epoch is {}, Loss is {:.8f}'.format(\n",
    "                DL_size_list[i_DL],i_Out+1,epoch+1,sum(loss)/len(loss)))\n",
    "        if flag==1:\n",
    "            print('Current DL size is {}, including {} BS.\\nCurrent Testing Epoch is {}, Loss is {:.8f}'.format(\n",
    "                DL_size_list[i_DL],i_Out+1,epoch+1,sum(loss)/len(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "eaedf654-428d-41fc-81b2-e690fb7379f3"
   },
   "outputs": [],
   "source": [
    "#train the network\n",
    "for i_DL in range(len(DL_size_list)):\n",
    "    DL_Result = {}\n",
    "    for i_Out in range(0,num_BS,1):\n",
    "        train_loader,test_loader,in_test,out_test = getLoader(i_DL,i_Out) \n",
    "        for epoch in range(max_epoch):\n",
    "            train_loss = []\n",
    "            for batch_idx,(x,label) in enumerate(train_loader):\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = net(x)\n",
    "                loss = criterion(label.to(torch.float32),y_hat.to(torch.float32))\n",
    "                train_loss.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            printS(i_DL,i_Out,epoch,train_loss,0)\n",
    "            test_loss = []\n",
    "            with torch.no_grad():\n",
    "                for batch_idx,(x,label) in enumerate(test_loader):\n",
    "                    x = x.to(device)\n",
    "                    label = label.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    y_hat = net(x)\n",
    "                    loss = criterion(label.to(torch.float32),y_hat.to(torch.float32))\n",
    "                    test_loss.append(loss)\n",
    "            printS(i_DL,i_Out,epoch,test_loss,1)\n",
    "        if epoch==(max_epoch-1):\n",
    "            print('End Train and Test of DL size {} and BS {} successfully.'.format(DL_size_list[i_DL],i_Out+1))\n",
    "        \n",
    "        #store DL_Result and save in .mat file\n",
    "        DL_Result['TX'+str(i_Out+1)+'Pred_Beams'] = y_hat\n",
    "        DL_Result['TX'+str(i_Out+1)+'Opt_Beams'] = out_test[:,:]\n",
    "    _,_,_,_,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    DL_Result['user_index'] = test_index\n",
    "    savemat('DLCB_code_output/DL_Result'+str(i_DL+1),DL_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "bc5340bf-27a7-412e-ad9d-d0c0f6bf9da8"
   },
   "outputs": [],
   "source": [
    "#save model to path\n",
    "path = './DLCB_code_output/model_train'+str(len(in_train))+'_test'+str(len(in_test))+'_epoch'+str(max_epoch)+'.pth'\n",
    "torch.save(net.state_dict(),path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
