{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "9a0adc66-ef6f-468b-b667-97186ee390bc"
   },
   "outputs": [],
   "source": [
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "131fff0e-8214-4071-990a-c3f6edd30aa8"
   },
   "outputs": [],
   "source": [
    "#input representations\n",
    "input_nodes=512\n",
    "output_nodes=2048\n",
    "middle_nodes=512\n",
    "#functional representations\n",
    "lr=1e-3\n",
    "dropout_rate=0.05\n",
    "max_epoch=10\n",
    "num_BS=4\n",
    "num_beam=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "3d45f6a1-c6f2-4fb7-b387-c1f06934713e"
   },
   "outputs": [],
   "source": [
    "#define a Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_nodes,middle_nodes)\n",
    "        self.fc2 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc3 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc4 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc5 = nn.Linear(middle_nodes,output_nodes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 4 hidden layers with each fc + relu + dropout\n",
    "        x = x.view(-1,512)\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p =dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc2(x)),p =dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc3(x)),p =dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc4(x)),p =dropout_rate,training = True)\n",
    "        # 1 output layer with fc + relu\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = x.view(-1,2048)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features*=s\n",
    "        return num_features\n",
    "    \n",
    "net=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "75c7d8a7-8005-4514-b036-370023a5820f"
   },
   "outputs": [],
   "source": [
    "#define Loss Function and Optimization method\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "6162d77c-8419-49b3-bf31-c1b53f56ba80"
   },
   "outputs": [],
   "source": [
    "#load datasets from matlab\n",
    "in_set_file = loadmat('DLCB_Dataset/DLCB_input.mat')\n",
    "in_set = in_set_file['DL_input']#in_set.shape=(54481,256)\n",
    "out_set_file = loadmat('DLCB_Dataset/DLCB_output.mat')\n",
    "out_set = out_set_file['DL_output']#out_set.shape=(54481,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b4eb2c10-0fc8-4726-9d42-472cec85976c"
   },
   "outputs": [],
   "source": [
    "#check size\n",
    "num_total_user=in_set.shape[0]\n",
    "print('Number of total users in input dataset is '+str(num_total_user))\n",
    "size_list_pr=[.001,.8]#[.001,.05,.1,.15,.2,.25,.3,.4,.45,.5,.55,.6,.65,.7,.75,.8,.85,.9,.95,1]\n",
    "size_list=[]\n",
    "for idx in range(len(size_list_pr)):\n",
    "    size_list.append(int(size_list_pr[idx]*num_total_user))\n",
    "print(size_list)\n",
    "#merge two lists one by one\n",
    "def mergeList(lst1,lst2):\n",
    "    return np.array([[i,j] for i,j in zip(lst1,lst2)]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "45cf92c7-db56-44e9-a641-d6b1e4e577e7"
   },
   "outputs": [],
   "source": [
    "class DataSetGenerator(data.Dataset):\n",
    "    def __init__(self,input_set,output_set):#input_set.shape= (43,256); output_set.shape=(43,2048)\n",
    "        self.input_set = input_set\n",
    "        self.output_set = output_set\n",
    "        real = {}\n",
    "        imag = {}\n",
    "        self.order = {}\n",
    "        for idx in range(len(input_set)): \n",
    "            real[idx] = np.float32(input_set[idx].real)\n",
    "            imag[idx] = np.float32(input_set[idx].imag)\n",
    "            self.order[idx] = mergeList(real[idx],imag[idx])\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        for idx in range(len(self.input_set)):\n",
    "            x = self.order[idx]\n",
    "            target = self.output_set[idx]\n",
    "        return x,target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a53d5d03-8999-4e0f-91d1-ae883f74549e"
   },
   "outputs": [],
   "source": [
    "#train the network\n",
    "def train():\n",
    "    for idx_size in range(len(size_list)):\n",
    "    \n",
    "        #assign values to set in_train, out_train, in_test, out_test\n",
    "        size = size_list[idx_size]\n",
    "        num_train = int(size*0.8)\n",
    "        num_test = int(num_total_user*0.2)\n",
    "        train_index = np.random.choice(range(0,num_total_user),size=num_train,replace=False)\n",
    "        rem_index = set(range(0,num_total_user))-set(train_index)\n",
    "        test_index = list(set(np.random.choice(list(rem_index),size=num_test,replace=False)))\n",
    "        in_train = in_set[train_index]\n",
    "        in_test = in_set[test_index]\n",
    "        out_train = out_set[train_index]\n",
    "        out_test = out_set[test_index]\n",
    "        print('Scene ['+str(1+idx_size)+']/['+str(len(size_list))+']. '+str(size)+' MUs are served now.')\n",
    "        print(str(num_train)+' training examples. '+str(num_test)+' test examples.')\n",
    "    \n",
    "        #divide every in_train, out_train example into real part and imaginary part\n",
    "        train_generator = DataSetGenerator(input_set = in_train, output_set = out_train)\n",
    "        test_generator = DataSetGenerator(input_set = in_test, output_set = out_test)\n",
    "        train_loader = data.DataLoader(dataset=train_generator, batch_size=100,shuffle=True)\n",
    "        test_loader = data.DataLoader(dataset=test_generator, batch_size=100,shuffle=True)\n",
    "    \n",
    "        for epoch in range(max_epoch):\n",
    "            run_loss=0\n",
    "            total_loss=[]\n",
    "        \n",
    "            for batch_idx,(x,target) in enumerate(train_loader):\n",
    "                y = net(x)\n",
    "                #calculate loss function\n",
    "                loss = criterion(target,y)\n",
    "                total_loss.append(loss)\n",
    "                #zero parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                #print loss statistics\n",
    "                if batch_idx%100==99:\n",
    "                    print('Train Epoch {}\\t Step {}\\t Loss {:.8f}'.format(epoch+1,batch_idx+1,sum(total_loss)/len(total_loss)),flush=True)\n",
    "    print('End of Training.')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "998c6a4b-d9ce-4436-94be-9c455198659d"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "state = {'model':net.state_dict(),'optimizer':optimizer.state_dict(),'epoch':epoch}\n",
    "path = './model.pth'\n",
    "torch.save(state,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5a6571fd-9355-4966-9e8e-3eb1780a15e5"
   },
   "outputs": [],
   "source": [
    "#test the network\n",
    "def test():\n",
    "    for idx_size in range(len(size_list)):\n",
    "        for epoch in range(max_epoch):\n",
    "            test_loss = 0\n",
    "            total_loss = []\n",
    "            with torch.no_grad():\n",
    "                for batch_idx,(x,target) in enumerate(test_loader):\n",
    "                    y_hat = net(x)\n",
    "                    test_loss = criterion(target,y_hat)\n",
    "                    total_loss.append(test_loss)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    print('Test set: Average loss:{.8f}, Accuracy:{}/{}({:.2f})').format(test_loss,sum(total_loss),len(total_loss),100.*test_loss/len(total_loss))\n",
    "    print('End of Testing.')\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
