{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "25759134-bff3-4be8-9036-4b296f44a10c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from scipy.io import loadmat,savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "1410d313-5282-4801-a4d9-48f3550de766"
   },
   "outputs": [],
   "source": [
    "#for docomo, 9 CUDAs are available in total\n",
    "cuda_num = 0\n",
    "num_device = torch.cuda.device_count()\n",
    "print('There are '+str(num_device)+' GPU(s). We will use CUDA '+str(cuda_num)+' in this program.')\n",
    "device = torch.device('cuda:'+str(cuda_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "48d08252-1e06-4a3c-9362-33811ba15db5"
   },
   "outputs": [],
   "source": [
    "#assign parameter values\n",
    "test_rate = .2\n",
    "lr = 1e-3\n",
    "min_epoch,max_epoch = 30,3000\n",
    "num_BS,num_beam = 4,512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "3ae79f73-f0fe-443a-99b8-d15f9964fb78"
   },
   "outputs": [],
   "source": [
    "#load datasets from files\n",
    "in_set_file = loadmat('DLCB_Dataset/DLCB_input.mat')\n",
    "in_set = in_set_file['DL_input']#in_set.shape=(54481,256)\n",
    "out_set_file = loadmat('DLCB_Dataset/DLCB_output.mat')\n",
    "out_set = out_set_file['DL_output']#out_set.shape=(54481,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "1846660c-8d85-4d6b-a270-49a6b38de0e4"
   },
   "outputs": [],
   "source": [
    "#define a Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        input_nodes,output_nodes,middle_nodes=512,512,512\n",
    "        self.fc1 = nn.Linear(input_nodes,middle_nodes)\n",
    "        self.fc2 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc3 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc4 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc5 = nn.Linear(middle_nodes,output_nodes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 4 hidden layers with each fc + relu + dropout\n",
    "        x = x.to(device)\n",
    "        dropout_rate=0.05\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc2(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc3(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc4(x)),p = dropout_rate,training = True)\n",
    "        # 1 output layer with fc + relu\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x  \n",
    "net = Net().to(device)\n",
    "\n",
    "#define Loss Function and Optimization method\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "7a2b3a43-8dda-4da6-bf41-e50dec97ecdc"
   },
   "outputs": [],
   "source": [
    "class DataSetGenerator(data.Dataset):\n",
    "    def __init__(self,input_set,output_set):\n",
    "        self.input_set = input_set\n",
    "        self.output_set = output_set\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        x = torch.from_numpy(self.input_set[index])\n",
    "        label = torch.from_numpy(self.output_set[index])\n",
    "        x,label=x.type(torch.float32),label.type(torch.float32)\n",
    "        return x,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a92e40b2-d017-4421-b18d-d53941da83bb"
   },
   "outputs": [],
   "source": [
    "#get num_total_user from in_set\n",
    "def getTotalUser(in_set):\n",
    "    return in_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e8ecd918-fbb3-4352-a1f2-c3448db68e11"
   },
   "outputs": [],
   "source": [
    "#get DL_size_list, 17 percentages are fixed according to the author\n",
    "def getDLSizeList():\n",
    "    DL_pr_list = np.array([.001,.05,.1,.15,.2,.25,.3,.35,.4,.45,.5,.55,.6,.65,.7,.75,.8])\n",
    "    return np.floor(DL_pr_list*num_total_user).astype(np.int64).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ac92feda-03d3-4acb-82e0-2284161e0cf5"
   },
   "outputs": [],
   "source": [
    "#get num_train and num_test, both are lists according to DL_size_list, num_total_user, test_rate\n",
    "def getAmount(DL_size_list,num_total_user,test_rate):\n",
    "    num_train=np.floor(np.asarray(DL_size_list)*.8).astype(np.int64).tolist()\n",
    "    num_test=int(num_total_user*test_rate)\n",
    "    return num_train,num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "883ca8f1-b91e-4df5-9065-4b2680d5b888"
   },
   "outputs": [],
   "source": [
    "#specifically for the i-th DL_size, return its in_train_pre,in_test_pre,out_train_pre,out_test_pre(all before any adjustments)\n",
    "def eachInOutPre(i,num_train,num_test,num_total_user,in_set,out_set):\n",
    "    train_index = np.random.choice(range(0,num_total_user),size=num_train[i],replace=False)\n",
    "    rem_index = set(range(0,num_total_user))-set(train_index)\n",
    "    test_index = list(set(np.random.choice(list(rem_index),size=num_test,replace=False)))\n",
    "    in_train_pre = in_set[train_index]\n",
    "    in_test_pre = in_set[test_index]\n",
    "    out_train_pre = out_set[train_index]\n",
    "    out_test_pre = out_set[test_index]\n",
    "    return in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "12e6757f-7987-4c7d-96fe-9f3659fd3690"
   },
   "outputs": [],
   "source": [
    "#arrange input into real part and imaginary part one by one\n",
    "def arrangeInput(lst):\n",
    "    re=np.array(lst).real\n",
    "    im=np.array(lst).imag\n",
    "    return np.stack((re,im),axis=2).reshape(lst.shape[0],lst.shape[1]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b50538e3-0f9e-44f6-9e9f-7e2df1d17048"
   },
   "outputs": [],
   "source": [
    "#specificially for i BS(s) in usage, divide output columns by num_beam\n",
    "def divideOutput(i,num_beam,lst):\n",
    "    return np.array(lst)[:,i*num_beam:(i+1)*num_beam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "dec84b56-a1f0-4cbb-8f12-94484c08a11d"
   },
   "outputs": [],
   "source": [
    "#for the i_DL-th DL_size and i_Out BS(s), generate and load datasets, where i_DL 0-16, i_Out 0-3\n",
    "def getLoader(i_DL,i_Out):\n",
    "    in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    in_train = arrangeInput(in_train_pre)\n",
    "    in_test = arrangeInput(in_test_pre)\n",
    "    out_train = divideOutput(i_Out,num_beam,out_train_pre)\n",
    "    out_test = divideOutput(i_Out,num_beam,out_test_pre)\n",
    "\n",
    "    train_generator = DataSetGenerator(input_set = in_train, output_set = out_train)\n",
    "    train_loader = data.DataLoader(dataset=train_generator, batch_size=128,shuffle=True)\n",
    "    \n",
    "    test_generator = DataSetGenerator(input_set = in_test, output_set = out_test)\n",
    "    test_loader = data.DataLoader(dataset=test_generator, batch_size=64,shuffle=True)\n",
    "    return train_loader,test_loader,in_test,out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "74ae0c8c-4e5e-4c54-823b-39fd9ac6e860"
   },
   "outputs": [],
   "source": [
    "num_total_user = getTotalUser(in_set)\n",
    "DL_size_list = getDLSizeList()\n",
    "num_train,num_test = getAmount(DL_size_list,num_total_user,test_rate)\n",
    "best_net = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "25d0e788-db79-485d-b01d-51e4bed31d57"
   },
   "outputs": [],
   "source": [
    "for i_DL in range(len(DL_size_list)):\n",
    "    for i_Out in range(0,num_BS,1):\n",
    "        net.to(device)\n",
    "        net.train()\n",
    "        train_loader,test_loader,in_test,out_test = getLoader(i_DL,i_Out)\n",
    "        test_loss=[]#average test loss of an epoch\n",
    "        min_loss=1e5#a large number\n",
    "        \n",
    "        for epoch in range(max_epoch):\n",
    "            for batch_idx,(x,label) in enumerate(train_loader):\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = net(x)\n",
    "                loss = criterion(label.to(torch.float32),y_hat.to(torch.float32))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            for batch_idx,(x,label) in enumerate(test_loader):\n",
    "                with torch.no_grad():\n",
    "                    x = x.to(device)\n",
    "                    label = label.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    y_hat = net(x)\n",
    "                    test_loss.append(1e4*criterion(label.to(torch.float32),y_hat.to(torch.float32)))\n",
    "            batch_loss = sum(test_loss)/len(test_loss)\n",
    "            if (epoch > min_epoch)and(batch_loss < min_loss):\n",
    "                min_loss = batch_loss\n",
    "                print('Min_loss is '+str(min_loss.items())+'*1e-4 at Epoch '+str(epoch))\n",
    "                saveNet='DLCB_code_output/cache/DL'+str(i_DL)+'Out'+str(i_Out)+'.pth'\n",
    "                torch.save({'epoch':epoch,\n",
    "                           'model_state_dict':net.state_dict(),\n",
    "                           'optimizer_state_dict':optimizer.state_dict(),\n",
    "                          'loss':loss},saveNet)               \n",
    "        if epoch==(max_epoch-1):\n",
    "            print('End Train and Test of DL size {} and BS {} successfully.'.format(DL_size_list[i_DL],i_Out+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "9defad78-57f9-4d51-afbc-21845871acf7"
   },
   "outputs": [],
   "source": [
    "#load previous net\n",
    "def loadSave(i_DL,i_Out):\n",
    "    saveNet='DLCB_code_output/cache/DL'+str(i_DL)+'Out'+str(i_Out)+'.pth'\n",
    "    return torch.load(saveNet,map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "bd0a3a62-2cbf-4af2-8d9b-567adaf0875a"
   },
   "outputs": [],
   "source": [
    "#continue to train and test under certain circumstances, train another 1000 epochs\n",
    "def trainContinue(i_DL,i_Out):\n",
    "    checkpoint=loadSave(i_DL,i_Out)\n",
    "    org_epoch=checkpoint['epoch']\n",
    "    extra_epoch=1e3\n",
    "    min_loss=checkpoint['loss']\n",
    "    net.load_state_dict=checkpoint['model_state_dict']\n",
    "    optimizer.load_state_dict=checkpoint['optimizer']\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    train_loader,test_loader,in_test,out_test = getLoader(i_DL,i_Out)\n",
    "    test_loss=[]#average test loss of an epoch\n",
    "    for epoch in range(extra_epoch):\n",
    "            \n",
    "        for batch_idx,(x,label) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(x)\n",
    "            loss = criterion(label.to(torch.float32),y_hat.to(torch.float32))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for batch_idx,(x,label) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = net(x)\n",
    "                test_loss.append(1e4*criterion(label.to(torch.float32),y_hat.to(torch.float32)))\n",
    "        batch_loss = sum(test_loss)/len(test_loss)\n",
    "        if batch_loss < min_loss:\n",
    "            min_loss = batch_loss\n",
    "            print('Min_loss is '+str(min_loss)+'*1e-4 at Epoch '+str(epoch+org_epoch))\n",
    "            torch.save({'epoch':epoch+org_epoch,\n",
    "                        'model_state_dict':net.state_dict(),\n",
    "                        'optimizer_state_dict':optimizer.state_dict(),\n",
    "                        'loss':loss},saveNet)               \n",
    "    if epoch==(max_epoch-1):\n",
    "        print('Another 1000 epochs of DL size {} and BS {} successfully.'.format(DL_size_list[i_DL],i_Out+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e29e8100-7bab-4dfe-a032-8093a5100001"
   },
   "outputs": [],
   "source": [
    "#the last Phase\n",
    "DL_Result={}\n",
    "for i_DL in range(len(DL_size_list)):\n",
    "    y_pred = np.zeros((num_test,num_beam))\n",
    "    for i_Out in range(0,num_BS,1):\n",
    "        _,test_loader,_,out_test = getLoader(i_DL,i_Out)\n",
    "        checkpoint=loadSave(i_DL,i_Out)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "        for batch_idx,(x,label) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                y_hat = net(x)\n",
    "                y_hat_np = y_hat.cpu().numpy()\n",
    "                for i in range(y_hat_np.shape[0]):\n",
    "                    y_pred[batch_idx*10+i] = y_hat_np[i]\n",
    "        DL_Result['TX'+str(i_Out+1)+'Pred_Beams'] = y_pred[:,:]\n",
    "        DL_Result['TX'+str(i_Out+1)+'Opt_Beams'] = out_test[:,:]\n",
    "    _,_,_,_,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    DL_Result['user_index'] = test_index\n",
    "    savemat('DLCB_code_output/DL_Result'+str(i_DL+1)+'.mat',DL_Result)\n",
    "    print('Savemat succeeds.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
