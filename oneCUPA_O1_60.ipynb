{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "458b8426-30ce-4234-a657-725703d873cd"
   },
   "outputs": [],
   "source": [
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat,savemat\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "cfcb4e2e-4ddb-402b-8794-0d0f39d332d1"
   },
   "outputs": [],
   "source": [
    "#for docomo, 9 CUDAs are available in total, we only use CUDA 0 is this program\n",
    "num_device = torch.cuda.device_count()\n",
    "print('There are '+str(num_device)+' GPUs. We will use CUDA 0 in this program.')\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "70b584f1-e7b8-4c05-8f52-9c57a5b5a973"
   },
   "outputs": [],
   "source": [
    "#assign parameter values\n",
    "input_nodes=512\n",
    "output_nodes=512\n",
    "middle_nodes=512\n",
    "test_rate=0.2\n",
    "min_epoch=30\n",
    "max_epoch=500\n",
    "lr=1e-3\n",
    "dropout_rate=0.05\n",
    "num_BS=4\n",
    "num_beam=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "f127cbef-442d-4ceb-abac-7a12c49f80e1"
   },
   "outputs": [],
   "source": [
    "#load datasets from .mat files\n",
    "in_set_file = loadmat('DLCB_Dataset/DLCB_input.mat')\n",
    "in_set = in_set_file['DL_input']#in_set.shape=(54481,256)\n",
    "out_set_file = loadmat('DLCB_Dataset/DLCB_output.mat')\n",
    "out_set = out_set_file['DL_output']#out_set.shape=(54481,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "70ba5c7c-49d2-4a9c-865c-5343c1a2d8d5"
   },
   "outputs": [],
   "source": [
    "#define a Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_nodes,middle_nodes)\n",
    "        self.fc2 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc3 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc4 = nn.Linear(middle_nodes,middle_nodes)\n",
    "        self.fc5 = nn.Linear(middle_nodes,output_nodes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 4 hidden layers with each fc + relu + dropout\n",
    "        x = x.to(device)\n",
    "        x = x.view(-1,512)\n",
    "        x = F.dropout(F.relu(self.fc1(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc2(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc3(x)),p = dropout_rate,training = True)\n",
    "        x = F.dropout(F.relu(self.fc4(x)),p = dropout_rate,training = True)\n",
    "        # 1 output layer with fc + relu\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x  \n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "\n",
    "#define Loss Function and Optimization method\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "7121682a-9cb8-4aaf-9e26-e20b69b5690e"
   },
   "outputs": [],
   "source": [
    "class DataSetGenerator(data.Dataset):\n",
    "    def __init__(self,input_set,output_set):\n",
    "        self.input_set = input_set\n",
    "        self.output_set = output_set\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        x = torch.from_numpy(self.input_set[index])\n",
    "        label = torch.from_numpy(self.output_set[index])\n",
    "        return torch.FloatTensor(x),torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "0caf0d52-66a6-48ab-ab02-c823e60d9a50"
   },
   "outputs": [],
   "source": [
    "#get num_total_user from in_set\n",
    "def getTotalUser(in_set):\n",
    "    return in_set.shape[0]\n",
    "num_total_user = getTotalUser(in_set)\n",
    "print(num_total_user)#num_total_user is an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "f9d185cd-de9e-4ed1-8526-e57c9aa60b77"
   },
   "outputs": [],
   "source": [
    "#get DL_size_list, 17 percentages are fixed according to the author\n",
    "def getDLSizeList():\n",
    "    DL_pr_list = np.array([.001,.05,.1,.15,.2,.25,.3,.35,.4,.45,.5,.55,.6,.65,.7,.75,.8])\n",
    "    return np.floor(DL_pr_list*num_total_user).astype(np.int64).tolist()\n",
    "##DL_size_list = getDLSizeList()\n",
    "##print(DL_size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "a3014917-b8e5-40a3-8bd0-f7dc0325bcaa"
   },
   "outputs": [],
   "source": [
    "#get num_train and num_test, both are lists according to DL_size_list, num_total_user, test_rate\n",
    "def getAmount(DL_size_list,num_total_user,test_rate):\n",
    "    num_train=np.floor(np.asarray(DL_size_list)*.8).astype(np.int64).tolist()\n",
    "    num_test=int(num_total_user*test_rate)\n",
    "    return num_train,num_test\n",
    "##num_train,num_test = getAmount(DL_size_list,num_total_user,test_rate)\n",
    "##print(num_train,num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5fcdf1f6-e24e-4db3-af8d-2c3bbbe0f4de"
   },
   "outputs": [],
   "source": [
    "#specifically for the i-th DL_size, return its in_train_pre,in_test_pre,out_train_pre,out_test_pre(all before any adjustments)\n",
    "def eachInOutPre(i,num_train,num_test,num_total_user,in_set,out_set):\n",
    "    train_index = np.random.choice(range(0,num_total_user),size=num_train[i],replace=False)\n",
    "    rem_index = set(range(0,num_total_user))-set(train_index)\n",
    "    test_index = list(set(np.random.choice(list(rem_index),size=num_test,replace=False)))\n",
    "    in_train_pre = in_set[train_index]\n",
    "    in_test_pre = in_set[test_index]\n",
    "    out_train_pre = out_set[train_index]\n",
    "    out_test_pre = out_set[test_index]\n",
    "    return in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index\n",
    "##in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index = eachInOutPre(16,num_train,num_test,num_total_user,in_set,out_set)\n",
    "##print(in_train_pre.shape,out_train_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "de6a9af2-12cc-40d7-882b-1ae3e3d519dd"
   },
   "outputs": [],
   "source": [
    "#arrange input into real part and imaginary part one by one\n",
    "def arrangeInput(lst):\n",
    "    re=np.array(lst).real\n",
    "    im=np.array(lst).imag\n",
    "    return np.stack((re,im),axis=2).reshape(lst.shape[0],lst.shape[1]*2)\n",
    "##in_train = arrangeInput(in_train_pre)\n",
    "##in_test = arrangeInput(in_test_pre)\n",
    "##print(in_train_pre.shape,in_train.shape)\n",
    "##print(in_train_pre[12][85],in_train[12][85*2],in_train[12][85*2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "f98e1475-e353-45e3-9d6c-00981b6e0823"
   },
   "outputs": [],
   "source": [
    "#specificially for i BS(s) in usage, divide output columns by num_beam\n",
    "def divideOutput(i,num_beam,lst):\n",
    "    return np.array(lst)[:,i*num_beam:(i+1)*num_beam]\n",
    "##out_train = divideOutput(2,num_beam,out_train_pre)\n",
    "##out_test = divideOutput(2,num_beam,out_test_pre)\n",
    "##print(out_train_pre.shape,out_train.shape)\n",
    "##print(out_train_pre[12][85+1024],out_train[12][85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "f9047c21-1860-4104-a007-bdf37527207e"
   },
   "outputs": [],
   "source": [
    "#for the i_DL-th DL_size and i_Out BS(s), generate and load datasets, where i_DL 0-16, i_Out 0-3\n",
    "def getLoader(i_DL,i_Out):\n",
    "    in_train_pre,out_train_pre,in_test_pre,out_test_pre,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    in_train = arrangeInput(in_train_pre)\n",
    "    in_test = arrangeInput(in_test_pre)\n",
    "    out_train = divideOutput(i_Out,num_beam,out_train_pre)\n",
    "    out_test = divideOutput(i_Out,num_beam,out_test_pre)\n",
    "\n",
    "    train_generator = DataSetGenerator(input_set = in_train, output_set = out_train)\n",
    "    train_loader = data.DataLoader(dataset=train_generator, batch_size=100,shuffle=True)\n",
    "    \n",
    "    test_generator = DataSetGenerator(input_set = in_test, output_set = out_test)\n",
    "    test_loader = data.DataLoader(dataset=test_generator, batch_size=10,shuffle=True)\n",
    "    return train_loader,test_loader,in_test,out_test\n",
    "##train_loader,test_loader,in_test,out_test = getLoader(12,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "229af813-8578-4d12-af4e-e9eaaf967c03"
   },
   "outputs": [],
   "source": [
    "#train and test the network, save the best net in best_net[17][4]\n",
    "best_net = {}\n",
    "for i_DL in range(len(DL_size_list)):\n",
    "    for i_Out in range(0,num_BS,1):\n",
    "        train_loader,test_loader,in_test,out_test = getLoader(i_DL,i_Out)\n",
    "        test_loss=[]#average test loss of an epoch\n",
    "        min_loss=10000#a big number\n",
    "        for epoch in range(max_epoch):\n",
    "            \n",
    "            for batch_idx,(x,label) in enumerate(train_loader):\n",
    "                x = x.to(device)\n",
    "                label = label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = net(x)\n",
    "                loss = criterion(label.to(torch.float32),y_hat.to(torch.float32))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            for batch_idx,(x,label) in enumerate(test_loader):\n",
    "                with torch.no_grad():\n",
    "                    x = x.to(device)\n",
    "                    label = label.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    y_hat = net(x)\n",
    "                    test_loss.append(1e4*criterion(label.to(torch.float32),y_hat.to(torch.float32)))\n",
    "            batch_loss = sum(test_loss)/len(test_loss)\n",
    "            if (epoch > min_epoch)and(batch_loss < min_loss):\n",
    "                min_loss = batch_loss\n",
    "                print('Min_loss is '+str(min_loss)+'*1e-4 at Epoch '+str(epoch))\n",
    "                best_net = copy.deepcopy(net.state_dict())\n",
    "                \n",
    "        saveNet = 'DLCB_code_output/cache/DL'+str(i_DL)+'Out'+str(i_Out)+'.pth'\n",
    "        torch.save(best_net,saveNet)                \n",
    "        if epoch==(max_epoch-1):\n",
    "            print('End Train and Test of DL size {} and BS {} successfully.'.format(DL_size_list[i_DL],i_Out+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "0656c333-d3af-4717-92f8-5e5a2edb4514"
   },
   "outputs": [],
   "source": [
    "#store DL_Result and save in .mat file\n",
    "DL_Result={}\n",
    "for i_DL in range(len(DL_size_list)):\n",
    "    y_pred = np.zeros((num_test[i_DL],num_beam))\n",
    "    for i_Out in range(0,num_BS,1):\n",
    "        _,test_loader,_,out_test = getLoader(i_DL,i_Out)\n",
    "        saveNet = 'DLCB_code_output/cache/DL'+str(i_DL)+'Out'+str(i_Out)+'.pth'\n",
    "        net.load_state_dict(torch.load(saveNet,map_location='cuda:0'))\n",
    "        net.to(device)\n",
    "        net.eval()\n",
    "        for batch_idx,(x,label) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                y_hat = net(x)\n",
    "                y_hat_np = y_hat.cpu().numpy()\n",
    "                for i in range(y_hat_np.shape[0]):\n",
    "                    y_pred[batch_idx*10+i] = y_hat_np[i]\n",
    "        DL_Result['TX'+str(i_Out+1)+'Pred_Beams'] = y_pred[:,:]\n",
    "        DL_Result['TX'+str(i_Out+1)+'Opt_Beams'] = out_test[:,:]\n",
    "    _,_,_,_,test_index = eachInOutPre(i_DL,num_train,num_test,num_total_user,in_set,out_set)\n",
    "    DL_Result['user_index'] = test_index\n",
    "    savemat('DLCB_code_output/DL_Result'+str(i_DL+1)+'.mat',DL_Result)\n",
    "    print('Savemat succeeds.\\n')\n",
    "    #check DL_Result\n",
    "    print(len(DL_Result['user_index']),DL_Result['TX2Pred_Beams'].shape,DL_Result['TX2Opt_Beams'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "1bc68aba-a348-4c79-9076-929a9a727de2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
